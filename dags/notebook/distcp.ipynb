{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03544861-0fe4-4885-9069-d67ee0aca45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T02:03:40.306761Z",
     "iopub.status.busy": "2024-01-31T02:03:40.306220Z",
     "iopub.status.idle": "2024-01-31T02:03:40.323725Z",
     "shell.execute_reply": "2024-01-31T02:03:40.323048Z",
     "shell.execute_reply.started": "2024-01-31T02:03:40.306720Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mye\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_spark\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skt'"
     ]
    }
   ],
   "source": [
    "from skt.ye import get_spark\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36daa6-0f1e-4c13-995d-b965f6515164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(args: Union[list, str], shell=True, timeout=5):\n",
    "    if shell:\n",
    "        if isinstance(args, str):\n",
    "            print('Running system command: {0}'.format(args))\n",
    "            proc = subprocess.Popen(args, shell=shell,stdout=subprocess.PIPE)\n",
    "        elif isinstance(args, list):\n",
    "            print('Running system command: {0}'.format(' '.join(args)))\n",
    "            proc = subprocess.Popen(' '.join(args), shell=shell,stdout=subprocess.PIPE)\n",
    "        else:\n",
    "            raise TypeError('input should be [List, str]')\n",
    "    else:\n",
    "        if isinstance(args, list):\n",
    "            proc = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "        else:\n",
    "            raise TypeError\n",
    "    try:\n",
    "        s_output, s_err = proc.communicate(timeout=timeout)\n",
    "    \n",
    "    except subprocess.TimeoutExpired:    \n",
    "        proc.kill()\n",
    "        s_output, s_err = proc.communicate()\n",
    "    \n",
    "    return_code =  proc.returncode    \n",
    "\n",
    "    return s_output.decode(\"utf-8\").strip() , s_err, return_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d767982-ab9d-4df1-8d40-d03e92f28f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_dt = datetime.strptime(current_dt, '%Y%m%d')\n",
    "execution_date_ago = (execution_dt - timedelta(days=1)).strftime('%Y/%m/%d')\n",
    "execution_dt = execution_dt.strftime('%Y/%m/%d')\n",
    "print(f'excution_dt: {execution_dt}')\n",
    "print(f'execution_dt_ago: {execution_date_ago}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ff704-d91b-4f6c-b906-910cd42a4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_ip = 'hdfs://172.27.1.237:8020//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049fcd7-6725-4f46-9935-8297b0ed78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "yesterday = (today - timedelta(days=1)).strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd7031-14de-4256-bfac-f40919a296f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05e62f-f06f-4b5e-8ff5-9e61acac8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_meta_path = f\"{hadoop_ip}/data/music/transform/flo/track_meta/{yesterday}/*\"\n",
    "output_format = (today - timedelta(days=1)).strftime('%Y/%m/%d')\n",
    "local_meta_path = f\"/data/adot/temp/jina/flo/meta/{output_format}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9286cf-9912-48c1-a314-14cd6d1e4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvm = spark._jvm\n",
    "jsc = spark._jsc\n",
    "fs = jvm.org.apache.hadoop.fs.FileSystem.get(jsc.hadoopConfiguration())\n",
    "if fs.exists(jvm.org.apache.hadoop.fs.Path(local_meta_path)):\n",
    "    print(f\"{local_meta_path} exists\")\n",
    "else:\n",
    "    print(f\"{local_meta_path} does not exists\")\n",
    "    \n",
    "    cmd_query = \"hdfs dfs -mkdir -p \" + local_meta_path + \";echo $?\"\n",
    "    s_output, stderr, return_code = run_cmd(cmd_query)\n",
    "    if return_code != 0:\n",
    "        print(stderr, return_code)\n",
    "        raise Exception(f'{cmd_query} fail')\n",
    "        \n",
    "    cmd_query = \"hadoop distcp -pb \"+remote_meta_path+ \" \" + local_meta_path + \";echo $?\"\n",
    "    s_output, stderr, return_code = run_cmd(cmd_query)\n",
    "    if return_code != 0:\n",
    "        print(stderr, return_code)\n",
    "        raise Exception(f'{cmd_query} fail')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
